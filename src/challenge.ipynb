{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Challenge LATAM\n",
    "\n",
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "En el desaf√≠o se pide implementar funciones que reciban los datos de tweets y realicen las consultas entregadas en 3 preguntas.\n",
    "\n",
    "Se explica que la soluci√≥n puede utilizar herramientas cloud, por lo que se decide utilizar Cloud Storage y Bigquery para almacenar y realizar consultas sobre los datos.\n",
    "\n",
    "Adem√°s, se decide experimentar con pandas para comparar los resultados en tiempo de ejecuci√≥n con Bigquery.\n",
    "\n",
    "Por otro lado, se asume que se puede realizar un preprocesamiento a los datos para facilitar las consultas. Adem√°s, de esta manera se disminuye el tiempo de ejecuci√≥n y de memoria utilizada, por lo que cumple con los requerimientos del desaf√≠o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis introductorio\n",
    "\n",
    "Primero se realiza un breve an√°lisis de los datos para entender su estructura y los datos que contienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "df = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'date', 'content', 'renderedContent', 'id', 'user', 'outlinks',\n",
       "       'tcooutlinks', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount',\n",
       "       'conversationId', 'lang', 'source', 'sourceUrl', 'sourceLabel', 'media',\n",
       "       'retweetedTweet', 'quotedTweet', 'mentionedUsers'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los datos contienen varias columnas y algunas de ellas contienen datos repetidos de otras columnas (source, sourceUrl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>tcooutlinks</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>media</th>\n",
       "      <th>retweetedTweet</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>username</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/ArjunSinghPanam/status/136...</td>\n",
       "      <td>2021-02-24 09:23:35+00:00</td>\n",
       "      <td>The world progresses while the Indian police a...</td>\n",
       "      <td>The world progresses while the Indian police a...</td>\n",
       "      <td>1364506249291784198</td>\n",
       "      <td>{'username': 'ArjunSinghPanam', 'displayname':...</td>\n",
       "      <td>[https://twitter.com/ravisinghka/status/136415...</td>\n",
       "      <td>[https://t.co/es3kn0IQAF]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://twitter.com/RaviSinghKA/statu...</td>\n",
       "      <td>[{'username': 'narendramodi', 'displayname': '...</td>\n",
       "      <td>ArjunSinghPanam</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/PrdeepNain/status/13645062...</td>\n",
       "      <td>2021-02-24 09:23:32+00:00</td>\n",
       "      <td>#FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...</td>\n",
       "      <td>#FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...</td>\n",
       "      <td>1364506237451313155</td>\n",
       "      <td>{'username': 'PrdeepNain', 'displayname': 'Pra...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'username': 'Kisanektamorcha', 'displayname'...</td>\n",
       "      <td>PrdeepNain</td>\n",
       "      <td>[üí™, üöú, üåæ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/parmarmaninder/status/1364...</td>\n",
       "      <td>2021-02-24 09:23:22+00:00</td>\n",
       "      <td>‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...</td>\n",
       "      <td>‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...</td>\n",
       "      <td>1364506195453767680</td>\n",
       "      <td>{'username': 'parmarmaninder', 'displayname': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>pa</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parmarmaninder</td>\n",
       "      <td>[ü§´, ü§î]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/13645...</td>\n",
       "      <td>2021-02-24 09:23:16+00:00</td>\n",
       "      <td>@ReallySwara @rohini_sgh watch full video here...</td>\n",
       "      <td>@ReallySwara @rohini_sgh watch full video here...</td>\n",
       "      <td>1364506167226032128</td>\n",
       "      <td>{'username': 'anmoldhaliwal', 'displayname': '...</td>\n",
       "      <td>[https://youtu.be/-bUKumwq-J8]</td>\n",
       "      <td>[https://t.co/wBPNdJdB0n]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>[{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'username': 'ReallySwara', 'displayname': 'S...</td>\n",
       "      <td>anmoldhaliwal</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/KotiaPreet/status/13645061...</td>\n",
       "      <td>2021-02-24 09:23:10+00:00</td>\n",
       "      <td>#KisanEktaMorcha #FarmersProtest #NoFarmersNoF...</td>\n",
       "      <td>#KisanEktaMorcha #FarmersProtest #NoFarmersNoF...</td>\n",
       "      <td>1364506144002088963</td>\n",
       "      <td>{'username': 'KotiaPreet', 'displayname': 'Pre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>und</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[{'previewUrl': 'https://pbs.twimg.com/media/E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KotiaPreet</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://twitter.com/ArjunSinghPanam/status/136...   \n",
       "1  https://twitter.com/PrdeepNain/status/13645062...   \n",
       "2  https://twitter.com/parmarmaninder/status/1364...   \n",
       "3  https://twitter.com/anmoldhaliwal/status/13645...   \n",
       "4  https://twitter.com/KotiaPreet/status/13645061...   \n",
       "\n",
       "                       date  \\\n",
       "0 2021-02-24 09:23:35+00:00   \n",
       "1 2021-02-24 09:23:32+00:00   \n",
       "2 2021-02-24 09:23:22+00:00   \n",
       "3 2021-02-24 09:23:16+00:00   \n",
       "4 2021-02-24 09:23:10+00:00   \n",
       "\n",
       "                                             content  \\\n",
       "0  The world progresses while the Indian police a...   \n",
       "1  #FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...   \n",
       "2  ‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...   \n",
       "3  @ReallySwara @rohini_sgh watch full video here...   \n",
       "4  #KisanEktaMorcha #FarmersProtest #NoFarmersNoF...   \n",
       "\n",
       "                                     renderedContent                   id  \\\n",
       "0  The world progresses while the Indian police a...  1364506249291784198   \n",
       "1  #FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...  1364506237451313155   \n",
       "2  ‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...  1364506195453767680   \n",
       "3  @ReallySwara @rohini_sgh watch full video here...  1364506167226032128   \n",
       "4  #KisanEktaMorcha #FarmersProtest #NoFarmersNoF...  1364506144002088963   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'username': 'ArjunSinghPanam', 'displayname':...   \n",
       "1  {'username': 'PrdeepNain', 'displayname': 'Pra...   \n",
       "2  {'username': 'parmarmaninder', 'displayname': ...   \n",
       "3  {'username': 'anmoldhaliwal', 'displayname': '...   \n",
       "4  {'username': 'KotiaPreet', 'displayname': 'Pre...   \n",
       "\n",
       "                                            outlinks  \\\n",
       "0  [https://twitter.com/ravisinghka/status/136415...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                     [https://youtu.be/-bUKumwq-J8]   \n",
       "4                                                 []   \n",
       "\n",
       "                 tcooutlinks  replyCount  retweetCount  ...  lang  \\\n",
       "0  [https://t.co/es3kn0IQAF]           0             0  ...    en   \n",
       "1                         []           0             0  ...    en   \n",
       "2                         []           0             0  ...    pa   \n",
       "3  [https://t.co/wBPNdJdB0n]           0             0  ...    en   \n",
       "4                         []           0             0  ...   und   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                             sourceUrl          sourceLabel  \\\n",
       "0   http://twitter.com/download/iphone   Twitter for iPhone   \n",
       "1  http://twitter.com/download/android  Twitter for Android   \n",
       "2  http://twitter.com/download/android  Twitter for Android   \n",
       "3           https://mobile.twitter.com      Twitter Web App   \n",
       "4   http://twitter.com/download/iphone   Twitter for iPhone   \n",
       "\n",
       "                                               media retweetedTweet  \\\n",
       "0                                               None            NaN   \n",
       "1  [{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...            NaN   \n",
       "2                                               None            NaN   \n",
       "3  [{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...            NaN   \n",
       "4  [{'previewUrl': 'https://pbs.twimg.com/media/E...            NaN   \n",
       "\n",
       "                                         quotedTweet  \\\n",
       "0  {'url': 'https://twitter.com/RaviSinghKA/statu...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                      mentionedUsers         username  \\\n",
       "0  [{'username': 'narendramodi', 'displayname': '...  ArjunSinghPanam   \n",
       "1  [{'username': 'Kisanektamorcha', 'displayname'...       PrdeepNain   \n",
       "2                                               None   parmarmaninder   \n",
       "3  [{'username': 'ReallySwara', 'displayname': 'S...    anmoldhaliwal   \n",
       "4                                               None       KotiaPreet   \n",
       "\n",
       "      emojis  \n",
       "0         []  \n",
       "1  [üí™, üöú, üåæ]  \n",
       "2     [ü§´, ü§î]  \n",
       "3         []  \n",
       "4         []  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que observo es que no se van a utilizar todas las columnas, por lo que se decide seleccionar solo las columnas que se van a utilizar.\n",
    "Pruebo algunas funciones para normalizar los datos y ver si se pueden realizar consultas m√°s eficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.json_normalize(df[\"user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"username\"] = df[\"user\"].apply(lambda x: x[\"username\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "df[\"emojis\"] = df[\"content\"].apply(emoji.distinct_emoji_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                []\n",
       "1         [üí™, üöú, üåæ]\n",
       "2            [ü§´, ü§î]\n",
       "3                []\n",
       "4                []\n",
       "            ...    \n",
       "117402           []\n",
       "117403           []\n",
       "117404           []\n",
       "117405           []\n",
       "117406          [üí™]\n",
       "Name: emojis, Length: 117407, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emojis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La informaci√≥n del usuario contiene principalmente datos relacionados solamente con detalles propios del usuario, sin relacionarse directamente con el tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \\n\\n@narendramodi @DelhiPolice Shame on you. \\n\\n#ModiDontSellFarmers \\n#FarmersProtest \\n#FreeNodeepKaur https://t.co/es3kn0IQAF'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://twitter.com/download/iphone'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sourceUrl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mentioned_users(mentioned_users):\n",
    "    if not mentioned_users:\n",
    "        return []\n",
    "    return [user[\"username\"] for user in mentioned_users]\n",
    "\n",
    "\n",
    "df[\"mentioned_users\"] = df[\"mentionedUsers\"].apply(get_mentioned_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecci√≥n de Columnas\n",
    "\n",
    "Para las consultas espec√≠ficas del desaf√≠o, me concentrar√© en las siguientes columnas:\n",
    "\n",
    "* date: Para identificar las fechas con m√°s tweets.\n",
    "* user: Para extraer el username.\n",
    "* content: Para contar emojis y menciones.\n",
    "* mentionedUsers: Para contar menciones.\n",
    "* id: Para identificar los tweets.\n",
    "\n",
    "## Preprocesamiento de Datos\n",
    "\n",
    "Para el preprocesamiento de los datos es necesario considerar las siguientes condiciones:\n",
    "\n",
    "1. Filtrar las columnas necesarias:\n",
    "\n",
    " * Seleccionamos solo las columnas que necesitamos para cada an√°lisis espec√≠fico.\n",
    "\n",
    "2. Normalizaci√≥n y transformaci√≥n:\n",
    "\n",
    " * Extraer usernames de las estructuras anidadas.\n",
    " * Extraer y contar emojis de los contenidos.\n",
    " * Extraer y contar menciones de las estructuras anidadas.\n",
    " * Normalizar la fecha a un formato simple YYYY-MM-DD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "BUCKET_NAME = \"farmers-protest-tweets\"\n",
    "FILE_NAME = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "destination_blob_name = \"raw/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_bucket(bucket_name):\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    try:\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name} found.\")\n",
    "    except storage.exceptions.NotFound:\n",
    "        bucket = storage_client.create_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name} not found. Created new bucket.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing bucket {bucket_name}: {e}\")\n",
    "        raise\n",
    "    return bucket\n",
    "\n",
    "\n",
    "def upload_file_to_blob(bucket, source_file_name, destination_blob_name):\n",
    "    try:\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "        print(\n",
    "            f\"File {source_file_name} uploaded to {destination_blob_name} in bucket {bucket.name}.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file {source_file_name} to bucket {bucket.name}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    bucket = get_or_create_bucket(bucket_name)\n",
    "    upload_file_to_blob(bucket, source_file_name, destination_blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket farmers-protest-tweets found.\n",
      "File farmers-protest-tweets-2021-2-4.json uploaded to raw/farmers-protest-tweets-2021-2-4.json in bucket farmers-protest-tweets.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(BUCKET_NAME, FILE_NAME, destination_blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import emoji\n",
    "import memory_profiler\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def extract_emojis(text: str):\n",
    "    \"\"\"\n",
    "    Extract emojis from the text\n",
    "    @param text: str\n",
    "    @return: str\n",
    "    \"\"\"\n",
    "    emojis = emoji.distinct_emoji_list(text)\n",
    "    return \",\".join(emojis) if emojis else None\n",
    "\n",
    "\n",
    "def extract_mentions(mentions: List[dict]):\n",
    "    \"\"\"\n",
    "    Extract usernames from the mentions\n",
    "    @param mentions: List[dict]\n",
    "    @return: str\n",
    "    \"\"\"\n",
    "    if mentions is not None:\n",
    "        users = [user[\"username\"] for user in mentions]\n",
    "        return \",\".join(users) if users else None\n",
    "\n",
    "\n",
    "@memory_profiler.profile\n",
    "def preprocess_twitter_data(file_path):\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    filtered_data = data[[\"date\", \"user\", \"content\", \"mentionedUsers\", \"id\"]]\n",
    "\n",
    "    filtered_data[\"username\"] = filtered_data[\"user\"].apply(lambda x: x[\"username\"])\n",
    "    filtered_data[\"emojis\"] = filtered_data[\"content\"].apply(extract_emojis)\n",
    "    filtered_data[\"mentions\"] = filtered_data[\"mentionedUsers\"].apply(extract_mentions)\n",
    "    filtered_data.drop(columns=[\"user\", \"mentionedUsers\"], inplace=True)\n",
    "    filtered_data.rename(columns={\"id\": \"tweet_id\", \"date\": \"tweet_date\"}, inplace=True)\n",
    "    filtered_data[\"tweet_date\"] = pd.to_datetime(filtered_data[\"tweet_date\"]).dt.date\n",
    "    filtered_data[\"tweet_date\"] = filtered_data[\"tweet_date\"].apply(\n",
    "        lambda x: x.strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    basename = os.path.basename(file_path)\n",
    "    basename = basename.split(\".\")[0]\n",
    "    filtered_name = f\"{basename}_filtered.json\"\n",
    "\n",
    "    filtered_data.to_json(filtered_name, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n",
      "preprocess_twitter_data.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['username'] = filtered_data['user'].apply(lambda x: x['username'])\n",
      "preprocess_twitter_data.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['emojis'] = filtered_data['content'].apply(extract_emojis)\n",
      "preprocess_twitter_data.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['mentions'] = filtered_data['mentionedUsers'].apply(extract_mentions)\n",
      "preprocess_twitter_data.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.drop(columns=['user', 'mentionedUsers'], inplace=True)\n",
      "Preprocessing completed and data saved to filtered_data.csv successfully.\n",
      "Filename: preprocess_twitter_data.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    128.0 MiB    128.0 MiB           1   @memory_profiler.profile\n",
      "    18                                         def preprocess_twitter_data(file_path):\n",
      "    19   2007.5 MiB   1879.5 MiB           1       data = pd.read_json(file_path, lines=True)\n",
      "    20   2007.9 MiB      0.5 MiB           1       filtered_data = data[['date', 'user', 'content', 'mentionedUsers', 'id']]\n",
      "    21   2007.9 MiB      0.0 MiB      234815       filtered_data['username'] = filtered_data['user'].apply(lambda x: x['username'])\n",
      "    22   2009.7 MiB      1.7 MiB           1       filtered_data['emojis'] = filtered_data['content'].apply(extract_emojis)\n",
      "    23   2010.9 MiB      1.2 MiB           1       filtered_data['mentions'] = filtered_data['mentionedUsers'].apply(extract_mentions)\n",
      "    24   2011.1 MiB      0.2 MiB           1       filtered_data.drop(columns=['user', 'mentionedUsers'], inplace=True)\n",
      "    25                                             \n",
      "    26                                             # Guardar el DataFrame filtrado en un nuevo archivo CSV\n",
      "    27   2011.7 MiB      0.6 MiB           1       filtered_data.to_csv('filtered_data.csv', index=False)\n",
      "    28                                         \n",
      "    29   2011.7 MiB      0.0 MiB           1       print(\"Preprocessing completed and data saved to filtered_data.csv successfully.\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the memory profiler\n",
    "!mprof run preprocess_twitter_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using last profile data.\n",
      "Figure(1260x540)\n"
     ]
    }
   ],
   "source": [
    "# Generate the memory usage plot\n",
    "!mprof plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy preprocesamiento\n",
    "\n",
    "* Habilitar la api de Cloud Build en GCP para deployar la cloud function que realizar√° el preprocesamiento de los datos\n",
    "* Para preprocesar los datos se utilizar√° una cloud function que se encargar√° de realizar el preprocesamiento de los datos y almacenarlos en un bucket de GCP.\n",
    "* Se utilizar√° un trigger de Cloud Storage para ejecutar la cloud function cada vez que se suba un archivo al bucket.\n",
    "* Se utilizar√° un bucket de GCP para almacenar los datos preprocesados.\n",
    "* El script de la cloud function se encuentra en el archivo `main.py` en la carpeta `preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a future Cloud SDK release, new functions will be deployed as 2nd gen  functions by default. This is equivalent to currently deploying new  with the --gen2 flag. Existing 1st gen functions will not be impacted and will continue to deploy as 1st gen functions.\n",
      "You can preview this behavior in beta. Alternatively, you can disable this behavior by explicitly specifying the --no-gen2 flag or by setting the functions/gen2 config property to 'off'.\n",
      "To learn more about the differences between 1st gen and 2nd gen functions, visit:\n",
      "https://cloud.google.com/functions/docs/concepts/version-comparison\n",
      "Deploying function (may take a while - up to 2 minutes)...‚†π                    \n",
      "For Cloud Build Logs, visit: https://console.cloud.google.com/cloud-build/builds;region=us-central1/50602127-cd2f-43fe-b775-7f0de0d7cf38?project=888729167142\n",
      "Deploying function (may take a while - up to 2 minutes)...done.                \n",
      "automaticUpdatePolicy: {}\n",
      "availableMemoryMb: 4096\n",
      "buildId: 50602127-cd2f-43fe-b775-7f0de0d7cf38\n",
      "buildName: projects/888729167142/locations/us-central1/builds/50602127-cd2f-43fe-b775-7f0de0d7cf38\n",
      "dockerRegistry: ARTIFACT_REGISTRY\n",
      "entryPoint: preprocess_twitter_data\n",
      "eventTrigger:\n",
      "  eventType: google.storage.object.finalize\n",
      "  failurePolicy: {}\n",
      "  resource: projects/_/buckets/farmers-protest-tweets\n",
      "  service: storage.googleapis.com\n",
      "ingressSettings: ALLOW_ALL\n",
      "labels:\n",
      "  deployment-tool: cli-gcloud\n",
      "maxInstances: 3000\n",
      "name: projects/semiotic-tracer-428121-b8/locations/us-central1/functions/preprocess_twitter_data\n",
      "runtime: python39\n",
      "serviceAccountEmail: semiotic-tracer-428121-b8@appspot.gserviceaccount.com\n",
      "sourceUploadUrl: https://storage.googleapis.com/uploads-110960159640.us-central1.cloudfunctions.appspot.com/26ca790e-5b6c-4873-bce8-e0fca39467fb.zip\n",
      "status: ACTIVE\n",
      "timeout: 540s\n",
      "updateTime: '2024-07-05T17:23:42.943Z'\n",
      "versionId: '16'\n"
     ]
    }
   ],
   "source": [
    "!gcloud functions deploy preprocess_twitter_data \\\n",
    "    --runtime python39 \\\n",
    "    --trigger-resource $BUCKET_NAME \\\n",
    "    --trigger-event google.storage.object.finalize \\\n",
    "    --source=preprocessing \\\n",
    "    --entry-point preprocess_twitter_data \\\n",
    "    --project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "dataset = \"farmers\"\n",
    "table_name = \"protest_tweets\"\n",
    "bucket_name = os.environ[\"BUCKET_NAME\"]\n",
    "\n",
    "file_name = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "basename = file_name.split(\".\")[0]\n",
    "filtered_file = f\"filtered/{basename}_filtered.json\"\n",
    "\n",
    "\n",
    "def create_dataset(dataset_name):\n",
    "    client = bigquery.Client()\n",
    "    dataset_id = f\"{client.project}.{dataset_name}\"\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = \"US\"\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print(f\"Created dataset {dataset.dataset_id}\")\n",
    "\n",
    "\n",
    "def create_table_from_csv_bucket(dataset_name, table_name, file_path, bucket_name):\n",
    "    client = bigquery.Client()\n",
    "    dataset_ref = client.dataset(dataset_name)\n",
    "    table_ref = dataset_ref.table(table_name)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "    job_config.autodetect = True\n",
    "    job_config.allow_quoted_newlines = True\n",
    "    uri = f\"gs://{bucket_name}/{file_path}\"\n",
    "    load_job = client.load_table_from_uri(uri, table_ref, job_config=job_config)\n",
    "    print(f\"Starting job {load_job.job_id}\")\n",
    "    load_job.result()\n",
    "    print(\"Job finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_from_csv_bucket(dataset, table_name, filtered_file, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1\n",
    "\n",
    "Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Pandas sin preprocesamiento\n",
    "\n",
    "Para este caso se consider√≥ realizar el conteo de los tweets utilizando el archivo de los datos sin preprocesar, para comparar el tiempo de ejecuci√≥n con el preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_FILE = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "FILTERED_FILE = \"farmers-protest-tweets-2021-2-4_filtered.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"]).dt.date\n",
    "    top_dates = data.groupby(\"date\").size().nlargest(10).index\n",
    "    result = []\n",
    "\n",
    "    for date in top_dates:\n",
    "        top_user = (\n",
    "            data[data[\"date\"] == date][\"user\"]\n",
    "            .apply(lambda x: x[\"username\"])\n",
    "            .value_counts()\n",
    "            .idxmax()\n",
    "        )\n",
    "        result.append((date, top_user))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 6.122255802154541 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(MAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version Pandas con preprocesamiento\n",
    "\n",
    "Para evaluar el rendimiento haciendolo con pandas, se utilizan funcionalidad de la librer√≠a para agrupar y contar los tweets por fecha y usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    data[\"tweet_date\"] = pd.to_datetime(data[\"tweet_date\"]).dt.date\n",
    "    top_dates = data.groupby(\"tweet_date\").size().nlargest(10).index\n",
    "    result = []\n",
    "\n",
    "    for date in top_dates:\n",
    "        top_user = data[data[\"tweet_date\"] == date][\"username\"].value_counts().idxmax()\n",
    "        result.append((date, top_user))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.5751049518585205 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(FILTERED_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Bigquery con preprocesamiento\n",
    "\n",
    "Para evaluar el rendimiento de Bigquery, se utilizan las funcionalidades de la librer√≠a para realizar la consulta y obtener los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "DATASET_ID = os.getenv(\"DATASET_ID\")\n",
    "TABLE_ID = os.getenv(\"TABLE_ID\")\n",
    "\n",
    "\n",
    "def q1_time() -> List[Tuple[datetime.date, str]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "    query = \"\"\"\n",
    "    with top_dates as (\n",
    "    SELECT DATE(date) as tweet_date, COUNT(*) as tweet_count\n",
    "        FROM `{dataset_id}.{table_id}`\n",
    "        GROUP BY DATE(date)\n",
    "        ORDER BY tweet_count DESC\n",
    "        LIMIT 10\n",
    "    ), user_count as (\n",
    "    SELECT t.tweet_date, f.username, max(t.tweet_count) tweet_count,\n",
    "    count(username) tweet_num, ROW_NUMBER() OVER (PARTITION BY DATE(t.tweet_date) ORDER BY COUNT(f.username) DESC) AS row_num\n",
    "    FROM `{dataset_id}.{table_id}` f\n",
    "    JOIN top_dates t\n",
    "    on (date(f.date) = t.tweet_date)\n",
    "    group by t.tweet_date, f.username\n",
    "    order by 3 desc)\n",
    "    SELECT \n",
    "        tweet_date, \n",
    "        username,\n",
    "        tweet_count\n",
    "    FROM user_count\n",
    "    WHERE row_num = 1\n",
    "    ORDER BY tweet_count DESC;\n",
    "    \"\"\".format(dataset_id=DATASET_ID, table_id=TABLE_ID)\n",
    "\n",
    "    query_job = bigquery_client.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    result = [(row.tweet_date, row.username) for row in results]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.7329068183898926 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de memoria\n",
    "\n",
    "Para optimizar la memoria utilizada se realiza una lectura linea por linea del archivo, se almacena los datos en diccionarios y se realiza el preprocesamiento de los datos en el mismo ciclo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    tweet_counts = {}\n",
    "    user_counts = {}\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            date = datetime.strptime(tweet[\"tweet_date\"], \"%Y-%m-%d\").date()\n",
    "            user = tweet[\"username\"]\n",
    "\n",
    "            if date not in tweet_counts:\n",
    "                tweet_counts[date] = 0\n",
    "                user_counts[date] = {}\n",
    "            tweet_counts[date] += 1\n",
    "\n",
    "            if user not in user_counts[date]:\n",
    "                user_counts[date][user] = 0\n",
    "            user_counts[date][user] += 1\n",
    "\n",
    "    top_dates = sorted(tweet_counts, key=tweet_counts.get, reverse=True)[:10]\n",
    "    result = [\n",
    "        (date, max(user_counts[date], key=user_counts[date].get), tweet_counts[date])\n",
    "        for date in top_dates\n",
    "    ]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.8252959251403809 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606', 12347),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437', 11296),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur', 11087),\n",
       " (datetime.date(2021, 2, 16), 'jot__b', 10443),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist', 10249),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu', 9625),\n",
       " (datetime.date(2021, 2, 15), 'jot__b', 9197),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160', 8502),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria', 8417),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91', 8204)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_memory(FILTERED_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2\n",
    "\n",
    "**Los top 10 emojis m√°s usados con su respectivo conteo.**\n",
    "\n",
    "Para esta pregunta se asume que:\n",
    "* Los emojis se cuenta una sola vez por tweet, sin importar cuantas veces se repita.\n",
    "* Se consideran los emojis que est√°n en el contenido del tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Pandas con preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    emojis_count = (\n",
    "        data[\"emojis\"]\n",
    "        .apply(lambda x: x.split(\",\") if x else [])\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "        .head(10)\n",
    "    )\n",
    "\n",
    "    result = [(emoji, count) for emoji, count in emojis_count.items()]\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.45200157165527344 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 3203),\n",
       " ('üòÇ', 1387),\n",
       " ('üöú', 1334),\n",
       " ('üåæ', 1298),\n",
       " ('‚ù§Ô∏è', 1205),\n",
       " ('‚úä', 1110),\n",
       " ('üáÆüá≥', 938),\n",
       " ('ü§£', 759),\n",
       " ('üëç', 634),\n",
       " ('üôèüèª', 580)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(FILTERED_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Pandas sin preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    emoji_counts = data[\"content\"].apply(extract_emojis).explode().value_counts()\n",
    "    result = [(emoji, count) for emoji, count in emoji_counts.head(10).items()]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 12.31988263130188 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 1789),\n",
       " ('üòÇ', 826),\n",
       " ('‚ù§Ô∏è', 762),\n",
       " ('üëç', 457),\n",
       " ('‚úä', 455),\n",
       " ('ü§£', 374),\n",
       " ('üôèüèª', 361),\n",
       " ('üëá', 329),\n",
       " ('üôèüèΩ', 277),\n",
       " ('üáÆüá≥', 269)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(MAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Bigquery con preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "DATASET_ID = os.getenv(\"DATASET_ID\")\n",
    "TABLE_ID = os.getenv(\"TABLE_ID\")\n",
    "\n",
    "\n",
    "def q2_time() -> List[Tuple[datetime.date, str]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "    emoji,\n",
    "    count(emoji) emoji_count\n",
    "    FROM (\n",
    "    SELECT\n",
    "        emojis,\n",
    "        SPLIT(emojis, ',') AS emoji_list,\n",
    "        ARRAY_LENGTH(SPLIT(emojis, ',')) length_a\n",
    "    FROM\n",
    "        `{dataset_id}.{table_id}`\n",
    "    WHERE emojis is not null\n",
    "    ORDER BY 3 DESC\n",
    "    ), UNNEST(emoji_list) AS emoji\n",
    "    GROUP BY emoji\n",
    "    ORDER BY 2 DESC\n",
    "    LIMIT 10;\n",
    "    \"\"\".format(dataset_id=DATASET_ID, table_id=TABLE_ID)\n",
    "\n",
    "    query_job = bigquery_client.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    result = [(row.emoji, row.emoji_count) for row in results]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.923854112625122 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 3203),\n",
       " ('üòÇ', 1387),\n",
       " ('üöú', 1334),\n",
       " ('üåæ', 1298),\n",
       " ('‚ù§Ô∏è', 1205),\n",
       " ('‚úä', 1110),\n",
       " ('üáÆüá≥', 938),\n",
       " ('ü§£', 759),\n",
       " ('üëç', 634),\n",
       " ('üôèüèª', 580)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import memory_profiler\n",
    "\n",
    "\n",
    "@memory_profiler.profile\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    emoji_counts = Counter()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            emojis = tweet.get(\"emojis\")\n",
    "            if emojis:\n",
    "                emoji_list = emojis.split(\",\")\n",
    "                emoji_counts.update(emoji_list)\n",
    "\n",
    "    top_10_emojis = emoji_counts.most_common(10)\n",
    "    result = [(emoji, count) for emoji, count in top_10_emojis]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /tmp/ipykernel_16414/1910330258.py\n",
      "Execution time: 1.6731047630310059 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 3203),\n",
       " ('üòÇ', 1387),\n",
       " ('üöú', 1334),\n",
       " ('üåæ', 1298),\n",
       " ('‚ù§Ô∏è', 1205),\n",
       " ('‚úä', 1110),\n",
       " ('üáÆüá≥', 938),\n",
       " ('ü§£', 759),\n",
       " ('üëç', 634),\n",
       " ('üôèüèª', 580)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(FILTERED_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 3\n",
    "\n",
    "El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Pandas con preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    data[\"mentions\"] = data[\"mentions\"].apply(lambda x: x.split(\",\") if x else [])\n",
    "    mentions_counts = Counter()\n",
    "    for mentions in data[\"mentions\"]:\n",
    "        mentions_counts.update(mentions)\n",
    "\n",
    "    top_10_mentions = mentions_counts.most_common(10)\n",
    "    result = [(mention, count) for mention, count in top_10_mentions]\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.49052858352661133 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(FILTERED_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Pandas sin preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    mentions = data[\"mentionedUsers\"].explode().dropna().apply(lambda x: x[\"username\"])\n",
    "    mention_counts = mentions.value_counts().nlargest(10)\n",
    "    result = list(mention_counts.items())\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 5.680205821990967 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(MAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versi√≥n Bigquery con preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "DATASET_ID = os.getenv(\"DATASET_ID\")\n",
    "TABLE_ID = os.getenv(\"TABLE_ID\")\n",
    "\n",
    "\n",
    "def q3_time() -> List[Tuple[datetime.date, str]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "        mention,\n",
    "        count(mention) mentions_count\n",
    "        FROM (\n",
    "        SELECT\n",
    "            SPLIT(mentions, ',') AS mention_list,\n",
    "            ARRAY_LENGTH(SPLIT(mentions, ',')) length_a\n",
    "        FROM\n",
    "            `{dataset_id}.{table_id}`\n",
    "        WHERE mentions is not null\n",
    "        ), UNNEST(mention_list) AS mention\n",
    "        GROUP BY mention\n",
    "        ORDER BY 2 DESC\n",
    "        LIMIT 10;\n",
    "    \"\"\".format(dataset_id=DATASET_ID, table_id=TABLE_ID)\n",
    "\n",
    "    query_job = bigquery_client.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    result = [(row.mention, row.mentions_count) for row in results]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.542377471923828 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import memory_profiler\n",
    "\n",
    "\n",
    "@memory_profiler.profile\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    mentions_counts = Counter()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            mentions = tweet.get(\"mentions\")\n",
    "            if mentions:\n",
    "                mention_list = mentions.split(\",\")\n",
    "                mentions_counts.update(mention_list)\n",
    "\n",
    "    top_10_mentions = mentions_counts.most_common(10)\n",
    "\n",
    "    result = [(mention, count) for mention, count in top_10_mentions]\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /tmp/ipykernel_16414/947806769.py\n",
      "Execution time: 1.8369793891906738 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_memory(FILTERED_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge-latam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
